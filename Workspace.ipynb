{"cells":[{"cell_type":"code","source":["%sh \n\ncwd=$(pwd)\ndoes_my_git_repo_exist=\"$cwd/acse-9-independent-research-project-kkf18\"\n\nif [ -d $does_my_git_repo_exist ] \nthen\n  echo \"Git repo exists!\"\n  echo \"Pulling master branch...\"\n  cd acse-9-independent-research-project-kkf18\n  git pull origin master\nelse\n  git clone https://github.com/msc-acse/acse-9-independent-research-project-kkf18.git\n  echo \"Git repo does not exist!\"\n  echo \"Cloning repo...\"\nfi"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%sh \n\ncd acse-9-independent-research-project-kkf18\ngit branch -a\ngit checkout Exploratory_Data_Analysis\ngit pull origin Exploratory_Data_Analysis"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import os\nimport sys\nimport importlib.util\nfrom pathlib import Path\n\n\n# Add repo path to our sys.path for importing modules from repo.\ndef import_mod(module_name):\n  cwd = os.getcwd()\n  my_git_repo_exists = Path('{}/acse-9-independent-research-project-kkf18'.format(cwd))\n\n  spec = importlib.util.spec_from_file_location(\"{}.py\".format(module_name), \"{}/{}.py\".format(my_git_repo_exists, module_name))\n  module = importlib.util.module_from_spec(spec)\n  spec.loader.exec_module(module)\n  \n  # load module into the sys module dictionary so it can be imported in\n  sys.modules[module_name] = module\n  \n  print(\"Import successful\")\n  \n  assert module_name in sys.modules.keys()\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Spark packages\nfrom pyspark.sql import functions as F\n\n# Standard packages\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport re\n\n# Homemade Modules\nimport_mod(\"Data_Engineering\")\nimport Data_Engineering as DET"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Load datas into notebook\ndf_01 = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/newdump_01.csv')\ndf_02 = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/newdump_02.csv')\ndf_OW1ql = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/Qliq.csv')\ndf_records = spark.read.format('csv').options(header='true', inferSchema='true', delimiter='|', encoding='iso-8859-1').load('/FileStore/tables/interences_filtered.csv')\n\n# Dumped Data:\n# Rename and cast types for each column\ndf_01 = df_01.select(\n      df_01[\"Unnamed: 0\"].alias(\"index\"),\n      F.to_timestamp(F.col(\"ts\").cast(\"string\"), \"dd-MMM-yy HH:mm:ss\").alias(\"datetime\"),\n      df_01[\"name\"].alias(\"tag\"),\n      df_01[\"value\"]\n)\n\ndf_02 = df_02.select(\n      df_02[\"Unnamed: 0\"].alias(\"index\"),\n      F.to_timestamp(F.col(\"ts\").cast(\"string\"), \"dd-MMM-yy HH:mm:ss\").alias(\"datetime\"),\n      df_02[\"name\"].alias(\"tag\"),\n      df_02[\"value\"]\n)\n\n# Clean up data using Data Engineering Tools\nDataEng = DET.GroupDataTools(df_01)\nDataEng.append_data(df_02)\nDataEng.is_null(DataEng.df)\nDataEng.df = DataEng.null2zero(\"value\", DataEng.df)\nDataEng.is_null(DataEng.df)\n\n# Tag Simplification\nDataEng.groupdata(\"tag\", \"datetime\", \"value\")\n\nr1 = re.compile('BRA-....-..-07.')\nr2 = re.compile('BRA-QT  -15-0077-RAW')\nOW1 = DataEng.splitdata_dict([r1, r2])\n\nr1 = re.compile('BRA-....-..-01.')\nr2 = re.compile('BRA-QT  -15-0017-RAW')\nOW3 = DataEng.splitdata_dict([r1, r2])\n\nr1 = re.compile('BRA-....-..-04.')\nOW2 = DataEng.splitdata_dict([r1])\n\n# Make a tag dictionary: Decode the tags!\ntag_names = {\n              \"BRA-PZT........\" : \"WHP\",\n              \"BRA-TT..-15....\" : \"WHT\",\n              \"BRA-FI.........\" : \"GLR\",\n              \"BRA-PT..-16....\" : \"GLP\",\n              \"BRA-PT..-13....\" : \"DHP\",\n              \"BRA-TT..-13....\" : \"DHT\",\n              \"BRA-HV.........\" : \"Choke\",\n              \"BRA-QT.........\" : \"ASD\"\n}\n\nOW1 = DataEng.decode_keys(OW1, tag_names)\nOW2 = DataEng.decode_keys(OW2, tag_names)\nOW3 = DataEng.decode_keys(OW3, tag_names)\n\n\n# Liquid Rate Data:\n# Add the additional columns to the oilwell dictionary\nOW1[\"LR\"] = df_OW1ql.select(\n                                   F.to_timestamp(F.col(\"DATE\").cast(\"string\"), \"MM/dd/yyyy\").alias(\"datetime\"),\n                                    df_OW1ql[\"Daily liquid rate [Sm3/d]\"].alias(\"value\")\n)\n\nOW1[\"OR\"] = df_OW1ql.select(\n                                   F.to_timestamp(F.col(\"DATE\").cast(\"string\"), \"MM/dd/yyyy\").alias(\"datetime\"),\n                                    df_OW1ql[\"Daily oil [Sm3/d]\"].alias(\"value\")\n)\n\n\n# Interference Records Data:\n# Translate column to english!\ndf_records, trans_dict = DataEng.translate_col(\"Description\", df_records)\n\n# Pick out only date and description columns\nOW1[\"Records\"] = df_records.select(\n                 F.to_timestamp(F.col(\"Date\").cast(\"string\"), \"MM/dd/yyyy\").alias(\"datetime\"),\n                 df_records[\"Description\"]\n)\n\nprint(\"\\nRaw data organised and imported as dictionaries: OW1, OW2, OW3\")\n\n\n# recorded interfaces begin 2017-01-20\nOW1[\"WHP_2017_2019\"] = OW1[\"WHP\"].where(OW1[\"WHP\"].datetime >= '2017-01-20')\n\nabrv_dict = {\n            \"due to sand\" : \"Choking due to sand\",\n            \"Valve test\" : \"Valve test\"\n}\n\n# Overlay time series graph with the records\nOW1[\"WHP_2017_2019\"] = DataEng.ts_overlay_records(OW1[\"WHP_2017_2019\"], OW1[\"Records\"], \"Description\", filt_dict=abrv_dict, translate_dict=trans_dict)\n\n# Remove any duplicates, and merge any related comments\nOW1[\"WHP_2017_2019\"] = DataEng.merge_duplicate(OW1[\"WHP_2017_2019\"], sqlContext)\n\n# Produce a discretisation of the columns\nOW1[\"WHP_2017_2019\"] = DataEng.discretise_col(OW1[\"WHP_2017_2019\"], \"Grouped\")\n\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Example of how to plot OW dictionaries\nts_dfs = [OW1[\"DHP\"], OW1[\"WHP\"], OW1[\"DHT\"], OW1[\"WHT\"], OW1[\"GLP\"]]\nts_labels = [\"DHP\", \"WHP\", \"DHT\", \"WHT\", \"GLP\"]\n\nge2016 = [df.where(df.datetime >= '2016-01-01') for df in ts_dfs]\n\nfig = DataEng.plot_ts(\"WHP, WHT, DHP, DHT, GLP over time\", \"datetime\", \"value\", ge2016, ts_labels)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Try to find the interventions thats occurred over the years\nts_dfs = [OW1[\"DHP\"], OW1[\"WHP\"], OW1[\"LR\"]]\nts_labels = [\"DHP\", \"WHP\", \"LR\"]\n\nge2016norm = [df.where(df.datetime >= '2016-01-11') for df in ts_dfs]\n\nfor i, df in enumerate(ge2016norm):\n  mean, std = df.select(F.mean(\"value\"), F.stddev(\"value\")).first()\n  ge2016norm[i] = df.withColumn(\"value_norm\", (F.col(\"value\")) / std)\n  ge2016norm[i] = ge2016norm[i].select(ge2016norm[i][\"datetime\"], ge2016norm[i][\"value_norm\"].alias(\"value\"))\n\nfig = DataEng.plot_ts(\"Standardised WHP, DHP, LR over time\", \"datetime\", \"value\", ge2016norm, ts_labels)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["ts_dfs = [OW1[\"DHP\"], OW1[\"WHP\"], OW1[\"LR\"]]\nts_labels = [\"DHP\", \"WHP\", \"LR\"]\n\nge2016norm = [df.where(df.datetime >= '2016-01-11') for df in ts_dfs]\n\nts_df = OW1[\"WHP\"].where(OW1[\"WHP\"].datetime >= '2017-01-20')\noverlay_df = OW1[\"WHP_2017_2019\"]\nyears = ['2017', '2018', '2019']\n\nfig = DataEng.plot_ts(\"Overlaid records for one parameter WHP\", \"datetime\", \"value\", [ts_df], [\"WHP\"], overlay=\"Grouped\", overlay_dfs=overlay_df, plot_yearly=years)\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["test_thresh = DataEng.threshold(OW1[\"WHP_2017_2019\"], 0.8)\ntest_avg = DataEng.avg_over_period(test_thresh, \"week\")\n\nts_labels = [\"Orig\", \"WHT_thresholded\", \"WHT_thresholded_avg\"]\nts_dfs = [OW1[\"WHP_2017_2019\"], test_thresh, test_avg]\nfig = DataEng.plot_ts(\"WHT_thresholded_avg\", \"datetime\", \"value\", ts_dfs, ts_labels, overlay=\"Grouped\", overlay_dfs=OW1[\"WHP_2017_2019\"])\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["years = ['2017', '2018', '2019']\nfig = DataEng.plot_ts(\"WHT_thresholded_avg\", \"datetime\", \"value\", ts_dfs, ts_labels, overlay=\"Grouped\", overlay_dfs=OW1[\"WHP_2017_2019\"], plot_yearly=years)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["test_thresh = DataEng.threshold(OW1[\"WHP_2017_2019\"], 0.8)\ntest_avg = DataEng.avg_over_period(test_thresh, \"week\")\n\nts_labels = [\"Orig\", \"WHT_thresholded\", \"WHT_thresholded_avg\"]\nts_dfs = [OW1[\"WHP_2017_2019\"], test_thresh, test_avg]\n\nyears = ['2017', '2018', '2019']\nfig = DataEng.plot_ts(\"WHT_thresholded_avg\", \"datetime\", \"value\", ts_dfs, ts_labels, overlay=\"Grouped\", overlay_dfs=OW1[\"WHP_2017_2019\"], plot_quarterly=years)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom livelossplot import PlotLosses\nfrom pycm import *\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as nnF\nimport csv\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset \nimport random\nimport itertools\nfrom sklearn.model_selection import StratifiedKFold\n\nimport seaborn as sns\n\n\ndef set_seed(seed):\n    \"\"\"\n    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n    torch.backends.cudnn.enabled   = False\n\n    return True\n\ndevice = 'cpu'\nif torch.cuda.device_count() > 0 and torch.cuda.is_available():\n    print(\"Cuda installed! Running on GPU!\")\n    device = 'cuda'\nelse:\n    print(\"No GPU available!\")\n\ndef correlate(data):\n  fig, ax = plt.subplots(figsize=(14,12))\n  colormap = plt.cm.RdBu\n  ax.set_title('Pearson Correlation of Features', y=1.05, size=15)\n  sns.heatmap(data.corr(), linewidths=0.1,vmax=1.0, \n              square=True, cmap=colormap, linecolor='white', annot=True, ax=ax)\n\n  display(fig)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["test_separator_data = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/testseparator_1.csv')\ntest_OW1 = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/OW1test_1.csv')\n\ntest_OW1 = test_OW1.select(F.to_timestamp(F.col(\"DATE\").cast(\"string\"), \"MM/dd/yyyy HH:mm\").alias(\"datetime\"), *[n for n in test_OW1.schema.names if not n == \"DATE\"])\ntest_OW1 = test_OW1.where(test_OW1.WHT != \"-\")\ntest_OW1 = test_OW1.withColumn(\"WHT_\", test_OW1[\"WHT\"].cast(\"double\"))\ntest_OW1 = test_OW1.drop(\"WHT\").withColumnRenamed(\"WHT_\", \"WHT\")\n\nprint(test_OW1.count())"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["correlate(test_OW1.toPandas())"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# OW1 = { n : test_OW1.select(F.to_timestamp(F.col(\"DATE\").cast(\"string\"), \"MM/dd/yyyy HH:mm\").alias(\"datetime\"), test_OW1[n].alias(\"value\")) for n in test_OW1.schema.names}\n# OW1 = { head : df.na.drop() for head, df in OW1.items() }"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["display(test_OW1.withColumn(\"value\", test_OW1[\"Q liq\"]))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["def dataframe2dictionary(df, date_head=\"datetime\"):\n  \"\"\"\n  Convert a dataframe of collected timeseries features into an organised dictionary. key=feature name : value=timeseries data of feature\n  \n  \"\"\"\n  \n  assert date_head in df.schema.names, \"no date column in given dataframe!\"\n  \n  OW_dict = {}\n  \n  for head in df.schema.names:\n    if head == date_head: continue\n    OW_dict[head] = df.select(df[date_head].alias(\"datetime\"), df[head].alias(\"value\"))\n  \n  return OW_dict\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["def dictionary2dataframe(OW_dict):\n  \"\"\"Convert a dictionary of timeseries features into a single dataframe of collected features.\n  \n  \"\"\"\n  \n  dfs = OW_dict[list(OW_dict.keys())[0]]\n  dfs = dfs.select(dfs[\"datetime\"], dfs[\"value\"].alias(list(OW_dict.keys())[0]))\n  \n  for i, (head, df) in enumerate(OW_dict.items()):\n    if i == 0: continue\n    df = df.select(df[\"datetime\"], df[\"value\"].alias(head))\n    dfs =  dfs.join(df, df.datetime == dfs.datetime, how=\"left\").drop(df.datetime)\n  \n  return dfs\n\n"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["OW_t = dataframe2dictionary(test_OW1)\nprint(OW_t)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["print(list(OW_t.keys())[0])"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["display(dictionary2dataframe(OW_t))"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["display(test_OW1)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Need a function to convert collected dataframe to dictionaries\n# Need a function to convert dictionaries into collected dataframe"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["test_OW1 = test_OW1.withColumn(\"value\", test_OW1[\"Q liq\"])\ntest_thresh = DataEng.threshold(test_OW1, 0.8)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# normalise the data\norig_heads = test_thresh.schema.names # schema names gets updated dynamically! So must be separate from the loop\n\nfor head in orig_heads:\n  if head == \"datetime\" or head == \"WELLNAME\" or head == \"value\": continue\n  mean, std = test_thresh.select(F.mean(head), F.stddev(head)).first()\n  test_thresh = test_thresh.withColumn(\"{}_\".format(head), (F.col(head)-mean)/std)\n  test_thresh = test_thresh.drop(head)\n  test_thresh = test_thresh.withColumnRenamed(\"{}_\".format(head), head)\n  \ndisplay(test_thresh)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["ts_labels = [\"Orig\", \"Thresholded\"]\nts_dfs = [test_OW1, test_thresh]\nfig = DataEng.plot_ts(\"Thresholded\", \"datetime\", \"value\", ts_dfs, ts_labels)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["display(test_thresh)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["from sklearn.model_selection import ShuffleSplit\nfrom sklearn.preprocessing import StandardScaler\n\npred_OW1 = test_thresh.select(\"datetime\", \"value\", \"WHP\", \"WHT\", \"Choke\", \"pbh\", \"Qgl\").na.drop().toPandas()\nX = pred_OW1[[\"WHP\", \"WHT\", \"Choke\", \"pbh\", \"Qgl\"]].values\ny = np.squeeze(pred_OW1[[\"value\"]].values)\n\nshuffler = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42).split(X, y)\nindices = [(train_idx, validation_idx) for train_idx, validation_idx in shuffler]   # indices[split][train, test]\n\nX_train, X_val = X[indices[0][0]], X[indices[0][1]]\ny_train, y_val = y[indices[0][0]], y[indices[0][1]]\n\ndate = np.squeeze(pred_OW1[[\"datetime\"]].values)\ndate_train, date_val = date[indices[0][0]], date[indices[0][1]]\n\n# print(X_train)\n# pred_OW1 = StandardScaler().fit_transform(pred_OW1)\n# print(pred_OW1)\n# print(\"Accuracy: %2.1f percent\" % (accuracy_score(y, y_pred)*100))"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["def kfold_datasets(n_splits, X_train_orig, y_train_orig, trans=True, verbatim=False):\n  '''Wrapper function that returns a list of train/val datasets which have been \n     subjected to the KFold method. \n  '''\n  \n  kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n  fold_train_loader = [] # list of shuffled training dataloaders\n  fold_validation_loader = [] # list of shuffled validation dataloaders\n\n  for train_index, test_index in kf.split(X_train_orig, y_train_orig):\n    if verbatim: print(\"TRAIN:\", train_index, \"Validation:\", test_index)\n    X_train, X_val = X_train_orig[train_index], X_train_orig[test_index]\n    y_train, y_val = y_train_orig[train_index], y_train_orig[test_index]\n\n    if verbatim: print(\"train size:\", X_train.shape, \"test size:\", X_val.shape)\n\n    # Convert to tensor\n    X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train)\n    X_val, y_val = torch.from_numpy(X_val).float(), torch.from_numpy(y_val)\n    \n    # Find mean std\n    mean1, std1 = torch.mean(X_train), torch.std(X_train)\n\n    # make Custom set\n    train_dataset = CustomImageTensorDataset(X_train, y_train.long(), transform=trans, mean=mean1, std=std1)\n    validation_dataset = CustomImageTensorDataset(X_val, y_val.long(), transform=False, mean=mean1, std=std1)\n\n    # initialize the data-loaders\n    fold_train_loader.append(DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4))\n    fold_validation_loader.append(DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0))\n    \ndef train_model_kfold(wd, lrt, fold_train_loader, fold_validation_loader):\n  \"\"\" function to easily train the model with weight_decay as input parameter.\n  \n      HOW TO RUN THE FUNCTION:\n      fold_train_loader, fold_validation_loader = kfold_datasets(5, X_train_orig, y_train_orig, False)\n      lloss, loss, acc = train_model_kfold(weight_decay[3], fold_train_loader, fold_validation_loader)\n  \"\"\"\n  \n  fold_liveloss = []\n  fold_loss = 0.\n  fold_acc = 0.\n  for fold in range(len(fold_train_loader)):\n    # CHANGE THE MODEL HERE:\n    model = LeNet5()\n\n    liveloss, val_loss, val_acc = train_model(wd, lrt, model, fold_train_loader[fold], fold_validation_loader[fold])\n    fold_liveloss.append(liveloss)\n    fold_loss += val_loss\n    fold_acc += val_acc\n    print(\"fold:\", fold)\n    \n  print(\"Averaged Accuracy: \", (fold_acc/len(fold_train_loader))*100)\n  return fold_liveloss, fold_loss, fold_acc"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# pred_OW1 = test_OW1.select(\"Q liq\", \"WHP\", \"WHT\", \"Choke\", \"pbh\", \"Qgl\").na.drop().toPandas()\n# print(pred_OW1)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression  # vectorised ML implementation\n\nmodel = LinearRegression(fit_intercept=True)\nmodel.fit(X_train, y_train)\ny_ = model.predict(X_train)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["print(model.coef_)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["train_plot = np.array(sorted(list(zip(date_train, y_train)))).transpose()\ntrain_plot1 = np.array(sorted(list(zip(date_train, y_)))).transpose()\n\nfig, ax = plt.subplots(figsize=(12,8))\nax.plot(train_plot[0], train_plot[1], \"*--\", label = 'truth')\nax.plot(train_plot1[0], train_plot1[1], \"*--\", label = 'model')\nax.legend(loc='best')\nax.grid(True)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["y_pred = model.predict(X_val)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["train_plot = np.array(sorted(list(zip(date_val, y_val)))).transpose()\ntrain_plot1 = np.array(sorted(list(zip(date_val, y_pred)))).transpose()\n\nfig, ax = plt.subplots(figsize=(12,8))\nax.plot(train_plot[0], train_plot[1], \"*--\", label = 'truth')\nax.plot(train_plot1[0], train_plot1[1], \"*--\", label = 'model')\nax.legend(loc='best')\nax.grid(True)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["OW1.keys()"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["display(OW1[\"LR\"])"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["# threshold out values\ntest_thresh = DataEng.threshold(test_OW1, 0.8)\n\n# normalise the data\norig_heads = test_thresh.schema.names # schema names gets updated dynamically! So must be separate from the loop\n\nfor head in orig_heads:\n  if head == \"datetime\" or head == \"WELLNAME\" or head == \"value\": continue\n  mean, std = test_thresh.select(F.mean(head), F.stddev(head)).first()\n  test_thresh = test_thresh.withColumn(\"{}_\".format(head), (F.col(head)-mean)/std)\n  test_thresh = test_thresh.drop(head)\n  test_thresh = test_thresh.withColumnRenamed(\"{}_\".format(head), head)\n\npred_OW1 = test_thresh.select(\"datetime\", \"value\", \"WHP\", \"WHT\", \"Choke\", \"pbh\", \"Qgl\").na.drop().toPandas()\nX = pred_OW1[[\"WHP\", \"WHT\", \"Choke\", \"pbh\", \"Qgl\"]].values\ny = np.squeeze(pred_OW1[[\"value\"]].values)\n\ndate = np.squeeze(pred_OW1[[\"datetime\"]].values)\n\nmodel = LinearRegression(fit_intercept=True)\nmodel.fit(X, y)\ny_ = model.predict(X_train)"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["print(model.coef_)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["Prod_Qliq_Scale = OW1[\"LR\"].where((OW1[\"LR\"].datetime >= '2018-06-01')).withColumnRenamed(\"value\", \"Qliq\")\navg_val = DataEng.avg_over_period(OW1[\"WHP\"].where((OW1[\"WHP\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"WHP\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"WHT\"].where((OW1[\"WHT\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"WHT\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"Choke\"].where((OW1[\"Choke\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"Choke\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"DHP\"].where((OW1[\"DHP\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"DHP\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"GLR\"].where((OW1[\"GLR\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"GLR\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["display(Prod_Qliq_Scale)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["# threshold out values\nProd_Qliq_Scale = Prod_Qliq_Scale.withColumn(\"value\", Prod_Qliq_Scale[\"Qliq\"])\nProd_Qliq_Scale = DataEng.threshold(Prod_Qliq_Scale, 0.8)\n\n# normalise the data\norig_heads = Prod_Qliq_Scale.schema.names # schema names gets updated dynamically! So must be separate from the loop\n\nfor head in orig_heads:\n  if head == \"datetime\" or head == \"WELLNAME\" or head == \"value\": continue\n  print(\"Standardising: \", head)\n  mean, std = Prod_Qliq_Scale.select(F.mean(head), F.stddev(head)).first()\n  Prod_Qliq_Scale = Prod_Qliq_Scale.withColumn(\"{}_\".format(head), (F.col(head)-mean)/std)\n  Prod_Qliq_Scale = Prod_Qliq_Scale.drop(head)\n  Prod_Qliq_Scale = Prod_Qliq_Scale.withColumnRenamed(\"{}_\".format(head), head)\n"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["pred_OW1 = Prod_Qliq_Scale.na.drop().toPandas()\n\npred_OW1 = pred_OW1.set_index(pred_OW1['datetime'])\npred_OW1 = pred_OW1.sort_index()\n\nX = pred_OW1[[\"WHP\", \"WHT\", \"Choke\", \"DHP\", \"GLR\"]].values\ny = np.squeeze(pred_OW1[[\"value\"]].values)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["y_pred = model.predict(X)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["fig, ax = plt.subplots(figsize=(12,8))\nax.plot(pred_OW1['datetime'], pred_OW1['value'], \"*--\", label = 'truth')\nax.plot(pred_OW1['datetime'], y_pred, \"*--\", label = 'model')\nax.legend(loc='best')\nax.grid(True)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["Prod_Qliq_Scale = OW1[\"LR\"].where((OW1[\"LR\"].datetime >= '2018-06-01')).withColumnRenamed(\"value\", \"Qliq\")\navg_val = DataEng.avg_over_period(OW1[\"WHP\"].where((OW1[\"WHP\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"WHP\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"WHT\"].where((OW1[\"WHT\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"WHT\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"Choke\"].where((OW1[\"Choke\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"Choke\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"DHP\"].where((OW1[\"DHP\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"DHP\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n\navg_val = DataEng.avg_over_period(OW1[\"GLR\"].where((OW1[\"GLR\"].datetime >= '2018-06-01')), \"day\")\nProd_Qliq_Scale = Prod_Qliq_Scale.join(avg_val.select(avg_val.datetime, avg_val.value.alias(\"GLR\")), Prod_Qliq_Scale.datetime == avg_val.datetime, how='left').drop(avg_val.datetime)\n"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["# threshold out values\nProd_Qliq_Scale = Prod_Qliq_Scale.withColumn(\"value\", Prod_Qliq_Scale[\"Qliq\"])\nProd_Qliq_Scale = DataEng.threshold(Prod_Qliq_Scale, 0.8)\n\n# normalise the data\norig_heads = Prod_Qliq_Scale.schema.names # schema names gets updated dynamically! So must be separate from the loop\n\nfor head in orig_heads:\n  if head == \"datetime\" or head == \"WELLNAME\" or head == \"value\": continue\n  print(\"Standardising: \", head)\n  mean, std = Prod_Qliq_Scale.select(F.mean(head), F.stddev(head)).first()\n  Prod_Qliq_Scale = Prod_Qliq_Scale.withColumn(\"{}_\".format(head), (F.col(head)-mean)/std)\n  Prod_Qliq_Scale = Prod_Qliq_Scale.drop(head)\n  Prod_Qliq_Scale = Prod_Qliq_Scale.withColumnRenamed(\"{}_\".format(head), head)\n\npred_OW1 = Prod_Qliq_Scale.select(\"datetime\", \"value\", \"WHP\", \"WHT\", \"Choke\", \"DHP\", \"GLR\").na.drop().toPandas()\npred_OW1 = pred_OW1.set_index(pred_OW1['datetime'])\npred_OW1 = pred_OW1.sort_index()\n\nX = pred_OW1[[\"WHP\", \"WHT\", \"Choke\", \"DHP\", \"GLR\"]].values\ny = np.squeeze(pred_OW1[[\"value\"]].values)\n\ndate = np.squeeze(pred_OW1[[\"datetime\"]].values)\n\nmodel = LinearRegression(fit_intercept=True)\nmodel.fit(X, y)\ny_ = model.predict(X)\n\nprint(model.coef_)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["separator = test_thresh.select(\"datetime\", \"value\", \"WHP\", \"WHT\", \"Choke\", \"pbh\", \"Qgl\").na.drop().toPandas()\nseparator = separator.where(separator[\"datetime\"] >= \"2018-06-01\")\ny_separator = np.squeeze(separator[[\"value\"]].values)\ndate = np.squeeze(separator[[\"datetime\"]].values)\n\nfig, ax = plt.subplots(figsize=(12,8))\nax.plot(pred_OW1['datetime'], pred_OW1['value'], \"--\", label = 'MIKON polynomial')\nax.plot(pred_OW1['datetime'], y_, \"--\", label = 'LR model')\nax.plot(date, y_separator, marker=\"+\", label = \"test separator\")\nax.legend(loc='best')\nax.grid(True)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":49}],"metadata":{"name":"Workspace","notebookId":1463798385420292},"nbformat":4,"nbformat_minor":0}